<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>C/C++ 防止头文件被重复引入</title>
    <link href="/2023/05/06/C++%E9%98%B2%E6%AD%A2%E5%A4%B4%E6%96%87%E4%BB%B6%E8%A2%AB%E9%87%8D%E5%A4%8D%E5%BC%95%E5%85%A5/"/>
    <url>/2023/05/06/C++%E9%98%B2%E6%AD%A2%E5%A4%B4%E6%96%87%E4%BB%B6%E8%A2%AB%E9%87%8D%E5%A4%8D%E5%BC%95%E5%85%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="C-防止头文件被重复引入">C++ 防止头文件被重复引入</h2><p>在 C/C++ 多文件编程中，可能会出现头文件被重复包含的情况。</p><p>例如在编译如下的程序时：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//book.h</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Book</span>&#123;<br><span class="hljs-comment">//.......</span><br>&#125;;<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//library.h</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&quot;book.h&quot;</span></span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Library</span>&#123;<br><span class="hljs-comment">//......</span><br>&#125;;<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//main.cpp</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&quot;book.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&quot;library.h&quot;</span></span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br><span class="hljs-comment">//......</span><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>编译器会提示 “Book 类型重定义” 的错误，而错误的原因也显而易见，编译器在预处理头文件时可以简单理解为将头文件直接打开并放在文件最开始，即在编译器眼中 main.cpp 的代码将会变成如下模样：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// #include&quot;book.h&quot; 展开book.h文件</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Book</span>&#123;<br><span class="hljs-comment">//.......</span><br>&#125;;<br><span class="hljs-comment">// #include&quot;library.h&quot; 展开library.h文件</span><br><span class="hljs-comment">// #include&quot;book.h&quot; library.h中展开book.h文件</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Book</span>&#123;<br><span class="hljs-comment">//.......</span><br>&#125;;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Library</span>&#123;<br><span class="hljs-comment">//......</span><br>&#125;;<br><span class="hljs-comment">// #include 之后的内容</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br><span class="hljs-comment">//......</span><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到同一个 Book 类型被重复定义了两次，而在 C++ 中这是不允许的。</p><p>当然我们也可以选择在 main.cpp 中去掉 <code>#include&quot;book.h&quot;</code>，这样也可以避免重复引入 Book 类，但实际上此方法并不适用于所有“重复引入”的场景。那我们怎样才能避免这个问题呢？对于该问题，有如下三种解决方法：</p><h3 id="使用宏定义避免重复引入">使用宏定义避免重复引入</h3><p>实际多文件开发中，为避免重复声明，通常会利用宏加入 include 防范 (include guard) :</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> _NAME_H</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _NAME_H</span><br><span class="hljs-comment">//头文件内容</span><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br></code></pre></td></tr></table></figure><p>对于如上代码，当程序中第一次引入该头文件时，由于 <code>_NAME_H</code> 尚未定义，所以会定义 <code>_NAME_H</code> 宏并保留 <code>#ifndef</code> 所包含的代码；而之后若想再次引入时，由于之前已经定义了 <code>_NAME_H</code> 宏，所以预处理时 <code>#ifndef</code> 所包含的代码就不会保留。</p><p>其中设置的宏名必须是独一无二的，不能与项目中其他宏的名称相同，否则会导致部分代码在预处理时被舍弃。</p><p>以刚才的代码为例，我们可以对 book.h 文件做如下修改：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> _BOOK_H</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _BOOK_H</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Book</span> &#123;<br>    <span class="hljs-comment">//......</span><br>&#125;;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br></code></pre></td></tr></table></figure><p>再次编译执行该程序就会发现不再报错，成功执行。</p><h3 id="使用-pragma-once-避免重复引入">使用 #pragma once 避免重复引入</h3><p>除前文所述的使用宏定义的方式之外，还可使用 <code>#pragma one</code> 预编译指令来避免该问题，<code>#pragma once</code> 是 C/C++ 中的一个非标准但广泛支持的预处理指令，它与 include guards 有相同的作用， 用于使当前文件在单次编译中只被包含一次。将其附加到指定文件的最开头位置，该文件就只会被包含一次。</p><p>仍旧以文章开头代码为例，#pragma once 使用方法如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// book.h</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> once</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Book</span> &#123;<br><span class="hljs-comment">//.......</span><br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>那么 #pragma once 和 #ifndef 有什么区别呢？</strong></p><h4 id="ifndef-方法">#ifndef 方法</h4><p>使用 #ifndef 的方法是受 C/C++ 语言标准支持的，不受任何编译器的限制，因此移植性更好。该方法不仅可以保证同一个文件不会被包含多次，也能保证内容完全相同的两个文件（或者代码片段）不会被不小心同时包含。但需要特别注意的是宏名不可重复。</p><p>但由于编译器每次都需要打开头文件才能判定是否有重复定义，因此<strong>在编译大型项目时，#ifndef 会使得编译时间相对较长，因此一些编译器逐渐开始支持 #pragma once 的方式。</strong></p><h4 id="pragma-once-方法">#pragma once 方法</h4><p>#pragma once 并不是C++的原生语法，而是编译器的一种支持，所以并不是所有的编译器都能够支持，一些较老版本的编译器就并不支持该指令，兼容性不是非常好。</p><blockquote><p>目前，几乎所有常见的编译器都支持 #pragma once 指令，甚至于 Visual Studio 2017 新建头文件时就会自带该指令。可以这么说，在 C/C++ 中，#pragma once 是一个非标准但却逐渐被很多编译器支持的指令。</p></blockquote><p>该指令可以使同一个文件不会被包含多次。但需要注意这里所说的 “同一个文件” 是指物理上的一个文件，而不是指内容相同的两个文件，因此如果某个头文件有多份拷贝，该方法不能保证它们不被重复包含。</p><p>此外该方法只能针对整个文件，而无法对文件中的某一段代码作 #pragma once 声明。</p><p>相对于 #ifndef 方法，该方法可以避免<strong>宏名冲突</strong>问题，且由于不涉及宏定义，当编译器遇到它时就会立刻知道当前文件只会被包含一次，因此效率很高；但该方法<strong>不支持跨平台！</strong></p><p>另外，这种方式不支持跨平台！</p><h3 id="使用-Pragma-操作符">使用 _Pragma 操作符</h3><p>C99 标准中新增加了一个和 #pragma 指令类似的 _Pragma 操作符，其可以看做是 #pragma 的增强版，不仅可以实现 #pragma 所有的功能，更重要的是，<strong>_Pragma 还能和宏搭配使用。</strong></p><p>_pragma 操作符与 sizeof 等操作符类似，将字符串字面量作为参数写在括号内即可，具体格式如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">_pragma(字符串字面量)<br></code></pre></td></tr></table></figure><p>因此若要实现与上例中 #pragma once 类似的效果，以文章开头代码为例，只需使用如下代码即可：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"> <span class="hljs-comment">// book.h</span><br>_pragma(<span class="hljs-string">&quot;once&quot;</span>)<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Book</span> &#123;<br><span class="hljs-comment">//.......</span><br>&#125;;<br></code></pre></td></tr></table></figure><p>而相比预处理指令 #pragma，由于 _pragma 是一个操作符，因此可以用在一些宏中，且在宏定义中是以内联方式使用的。</p><p>此处以设置编译器优化等级为例，如果使用#pragma，则需要这样写：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> OPT_LEVEL n   <span class="hljs-comment">// n为优化等级</span></span><br></code></pre></td></tr></table></figure><p>由于每次都需要重复写 <code>#pragma OPT_LEVEL n</code>  (可能更长) 相对来说比较麻烦，违反编程的 DRY 原则，因此我们可能会想到利用宏定义来简化书写，例如我们可以定义如下的宏：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> OPT_L(x) #<span class="hljs-keyword">pragma</span> OPT_LEVEL x</span><br></code></pre></td></tr></table></figure><p>之后我们就只需要写 <code>OPT_L(n)</code> 即可，然而这在 C90 中并不能实现，字符 “#” 在预处理指令中有特殊的用途，编译器会将指令中的数字符号（“#”）解释为字符串化运算符（#），例如我们定义一个宏 <code>#define C90(x) #x</code> ，那么 <code>C90(test)</code> 的替换结果为 <code>&quot;test&quot;</code>。也就是，通过 #define 来定义一个关于#pragma 的宏是不可行的。</p><p>而新的关键字 <strong>_pragma</strong> 就很好的解决了这个问题，由于 _pragma并没有字符 “#” ，因此可以直接定义宏：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> PRAGMA(X) __pragma(#X)</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> OPT_L(X) PRAGMA(OPT_LEVEL X)</span><br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>对于本文中提到的 3 种避免头文件被重复包含的方法，其中 #pragma once 和 _Pragma(“once”)  可算作是同一类，其特点是编译效率高，但可移植性差 (编译器不支持，会发出警告，但不会中断程序的执行)；而 #ifndef 的特点是可移植性高，编译效率差。实际使用中我们可根据实际情况，挑选最符合实际需要的解决方案。</p><blockquote><p>事实上，无论是 C 语言还是 C++，为防止用户重复引入系统库文件，几乎所有库文件中都采用了以上 3 种结构中的一种，这也是为什么重复引入系统库文件编译器也不会报错的原因。</p></blockquote><p>另外在某些场景中，考虑到编译效率和可移植性，#pragma once 和 #ifndef 经常被结合使用来避免头文件被重复引入，例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> once</span><br><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> _STUDENT_H</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _STUDENT_H</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Book</span> &#123;<br>    <span class="hljs-comment">//......</span><br>&#125;;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br></code></pre></td></tr></table></figure><p>当编译器可以识别 #pragma once 时，则整个文件仅被编译一次；反之，即便编译器不识别 #pragma once 指令，此时仍有 #ifndef 在发挥作用。</p>]]></content>
    
    
    
    <tags>
      
      <tag>C/C++</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch安装 [Windows10/cuda11.6]</title>
    <link href="/2023/04/19/Pytorch%E5%AE%89%E8%A3%85/"/>
    <url>/2023/04/19/Pytorch%E5%AE%89%E8%A3%85/</url>
    
    <content type="html"><![CDATA[<p>本文步骤中所使用的环境：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">版本: PyTorch GPU @cuda11.6<br>系统: Windows10<br>显卡: GTX1650<br>cuda版本: release 11.6, V11.6.112<br>conda版本: conda 23.1.0<br></code></pre></td></tr></table></figure><h2 id="版本检查">版本检查</h2><h3 id="Python版本">Python版本</h3><p>版本都是对应的，很有可能某一步版本有差别就会出问题，我使用的 python 环境是 3.8，若想使用其他版本请移步其他博客参考.</p><h4 id="有-Conda">有 Conda</h4><p>直接使用 conda 创建一个新的 python 虚拟环境即可，python 版本选择 3.8 (本文直接使用默认的版本3.8.16, 不确定是否有影响).</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda update conda<br>conda create -n your_env_name python=3.8<br><span class="hljs-meta prompt_"># </span><span class="language-bash">例如 conda create  -n py38-gpu python=3.8</span><br></code></pre></td></tr></table></figure><h4 id="无-Conda">无 Conda</h4><p>无 Conda 的话建议下一个 Anaconda 😄, 后续可以出 Anaconda 的安装教程.</p><p>不想下 Conda 也可选择重新装 python 环境，或者移步其他版本合适的博客，在命令行中输入如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">python -V<br></code></pre></td></tr></table></figure><p>本人使用的是 Pyhton 3.8.16，尽可能也选择一样的版本，或者 python 3.8，否则后续步骤可能有略微差异，不能保证后续无错误.</p><p><img src="/2023/04/19/Pytorch%E5%AE%89%E8%A3%85/pic1.png" alt="Python版本"></p><h3 id="Cuda-版本">Cuda 版本</h3><p>如果你的显卡是 AMD/ATI 那可以退出本篇了😆 ，A 卡不支持 CUDA 。</p><p>我的显卡是 NVIDIA GeForce GTX 1650 4GB ( 菜的一批，写写课程作业得了😢 )</p><p>在终端中输入<code>nvidia-smi</code> 查看 CUDA 版本，如下图显示 CUDA Version：11.6</p><p><img src="/2023/04/19/Pytorch%E5%AE%89%E8%A3%85/pic2.png" alt="Cuda版本"></p><p>如果 <code>nvidia-smi</code> 无法查看，可能是显卡太古老或者是显卡驱动有问题，更新一下显卡驱动试试看 (<s>虽然更新可能会出现负优化的情况😆</s>)。</p><p>如果还未安装 CUDA，可以去官网查一下 CUDA Toolkit 所需最低驱动程序版本，查看自己的显卡驱动是否支持 CUDA 11.6，若符合的话去官网安装 CUDA Tooolkit 和 对应版本的 cuDNN 即可。</p><p>如下表格 Windows x86_64 系统只要显卡驱动版本不低于 452.39 即可安装 CUDA 11.6。</p><table><thead><tr><th>CUDA Toolkit</th><th>Minimum Required Driver Version for CUDA Minor Version Compatibility*</th><th></th></tr></thead><tbody><tr><td></td><td>Linux x86_64 Driver Version</td><td>Windows x86_64 Driver Version</td></tr><tr><td>CUDA 12.1.x</td><td>&gt;=525.60.13</td><td>&gt;=527.41</td></tr><tr><td>CUDA 12.0.x</td><td>&gt;=525.60.13</td><td>&gt;=527.41</td></tr><tr><td>CUDA 11.8.x</td><td>&gt;=450.80.02</td><td>&gt;=452.39</td></tr><tr><td>CUDA 11.7.x</td><td>&gt;=450.80.02</td><td>&gt;=452.39</td></tr><tr><td>CUDA 11.6.x</td><td>&gt;=450.80.02</td><td>&gt;=452.39</td></tr><tr><td>CUDA 11.5.x</td><td>&gt;=450.80.02</td><td>&gt;=452.39</td></tr><tr><td>CUDA 11.4.x</td><td>&gt;=450.80.02</td><td>&gt;=452.39</td></tr><tr><td>CUDA 11.3.x</td><td>&gt;=450.80.02</td><td>&gt;=452.39</td></tr><tr><td>CUDA 11.2.x</td><td>&gt;=450.80.02</td><td>&gt;=452.39</td></tr><tr><td>CUDA 11.1 (11.1.0)</td><td>&gt;=450.80.02</td><td>&gt;=452.39</td></tr><tr><td>CUDA 11.0 (11.0.3)</td><td>&gt;=450.36.06**</td><td>&gt;=451.22**</td></tr></tbody></table><h2 id="开始安装PyTorch">开始安装PyTorch</h2><p>直接去<a href="https://pytorch.org">官网</a>，点击 Install，然后选择相应的版本，如下图可以看到会给出一个安装命令，~~直接在命令行输入该命令即可完成PyTorch+cuDNN+torchvision全部的安装！~~当然要是这么简单的话就好了😢，直接下载的话非常非常的慢，除非你的网络可以流畅的访问外网…</p><p><img src="/2023/04/19/Pytorch%E5%AE%89%E8%A3%85/pic3.png" alt="Pytorch官网安装"></p><p>当然还有一个问题就是这个页面中竟然没有 CUDA 11.6 的选项😭，但是没有关系我们可以点击图中表格上方的 <font color="red">install previous verisons of PyTorch</font> 选项在历史版本中找到 CUDA 11.6 对应的 Pytorch 版本：</p><p><img src="/2023/04/19/Pytorch%E5%AE%89%E8%A3%85/pic4.png" alt="历史版本"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116<br></code></pre></td></tr></table></figure><p>很好现在回到我们访问外网下载龟速的问题上，<s>如果不在国外，又不想使用魔法的话</s>，直接在浏览器中打开安装命令后面的网址 <a href="https://download.pytorch.org/whl/cu116%EF%BC%8C%E6%89%93%E5%BC%80%E5%90%8E%E7%95%8C%E9%9D%A2%E5%A6%82%E4%B8%8B%EF%BC%9A">https://download.pytorch.org/whl/cu116，打开后界面如下：</a></p><p><img src="/2023/04/19/Pytorch%E5%AE%89%E8%A3%85/pic5.png" alt="Pytorch组件"></p><p>再次回到刚刚的安装命令，可以看到我们需要安装 torch、torchvision、torchaudio 这三个东西：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116<br></code></pre></td></tr></table></figure><p>分别点击相应的链接，找到相应的版本下载即可。</p><p>首先是 torch， 点击之后进入到新页面可以看到很多.whl后缀的文件，现在我们就需要根据自己的环境来选择合适的版本，例如我的环境是：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">CUDA版本:11.6</span><br><span class="hljs-section">Python版本:3.8</span><br><span class="hljs-section">操作系统版本:Win10</span><br><span class="hljs-section">处理器:AMD R7-4800H 64位</span><br></code></pre></td></tr></table></figure><p>即对应可以下载如下图的版本 (可以直接 <code>CTRL + F</code> 搜索)：</p><p><img src="/2023/04/19/Pytorch%E5%AE%89%E8%A3%85/pic6.png" alt="对应torch版本"></p><p><strong>其中 torch-1.12.0 就是 torch 的版本，cu116 就是 cuda 版本，cp38 就是 Python的版本，win_amd64 就是 64 位 windows 系统。</strong></p><p>点击该链接就会开始下载，当然如果直接使用浏览器网页下载可能依旧会很慢，并且网络较差文件比较大的时候很有可能出问题导致下载失败，这个时候我们可以选择使用下载器来下载，找个好用的下载器 ( 正经下载器，例如迅雷 )，复制链接下载即可。</p><p>之后的 torchvision 和 torchaudio 同理，按照刚才我们说的命名方式，找到合适的版本，然后下载即可，全部下载完之后就可以开始安装了。</p><h3 id="手动安装">手动安装</h3><p>以 pip 为例我们只需要指定安装包的路径即可，找到我们下载的 <code>*.whl</code> 文件目录，在文件夹的目录栏输入 <code>cmd</code> 后点击回车即可快速打开一个当前目录下的命令行：</p><p><img src="/2023/04/19/Pytorch%E5%AE%89%E8%A3%85/pic7.png" alt="当前目录下打开cmd"></p><p>也可以 <code>Win + R</code> 输入 <code>cmd</code> 打开命令行之后转过，总之在该目录下打开一个终端即可。</p><p>之后执行命令 <code>pip install ./安装包名字.whl</code> 即可安装，例如 <code>pip install ./torch-1.12.0+cu116-cp38-cp38-win_amd64.whl</code> ，同理其他的安装包也是这样安装。</p><h2 id="检验是否成功">检验是否成功</h2><p>使用 Python (注意如果用的是 conda，记得切换到对应的虚拟环境) 执行如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-built_in">print</span>(torch.__version__)<br><span class="hljs-built_in">print</span>(torch.cuda.is_available())<br></code></pre></td></tr></table></figure><p><img src="/2023/04/19/Pytorch%E5%AE%89%E8%A3%85/pic8.png" alt="检验Pytorch版本"></p><p>如果得到如图所示的输出，那么说明安装成功，可以愉快地使用 GPU 进行计算了！</p><p>如果没有出现 cuxxx 且打印了 False 那说明安装出了问题，重新过一遍步骤看是否有遗漏有差错吧…</p><h3 id="跑个程序测试下">跑个程序测试下</h3><p>以防万一，我们可以随便找一个测试程序运行一下看看是否真的使用 GPU 进行计算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> autograd<br><br><span class="hljs-built_in">print</span>(torch.__version__)<br><span class="hljs-built_in">print</span>(torch.cuda.is_available())<br><br>a = torch.randn(<span class="hljs-number">10000</span>,<span class="hljs-number">5000</span>)<br>b = torch.randn(<span class="hljs-number">5000</span>,<span class="hljs-number">10000</span>)<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;device\t\tLoadData Time\tComputing time\tTotal time&quot;</span>)<br><span class="hljs-comment"># # 设备选择 cpu</span><br>device = torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>)<br><span class="hljs-comment"># 加载数据</span><br>beginTime = time.time()<br>a = a.to(device)<br>b = b.to(device)<br>endTime = time.time()<br>loadTime = endTime - beginTime<br><span class="hljs-comment"># 计算矩阵</span><br>beginTime = time.time()<br>c = torch.matmul(a,b)<br>endTime = time.time()<br>calTime = endTime - beginTime<br><br>totalTime = loadTime + calTime<br><span class="hljs-built_in">print</span>(device,<span class="hljs-string">&quot;\t\t%.5f\t\t%.5f\t\t%.5f&quot;</span>%(loadTime,calTime,totalTime))<br><br><br><span class="hljs-comment"># 设备选择 gpu</span><br>device = torch.device(<span class="hljs-string">&#x27;cuda&#x27;</span>)<br><span class="hljs-comment"># 加载数据</span><br>beginTime = time.time()<br>a = a.to(device)<br>b = b.to(device)<br>endTime = time.time()<br>loadTime = endTime - beginTime<br><span class="hljs-comment"># 计算矩阵</span><br>beginTime = time.time()<br>c = torch.matmul(a,b)<br>endTime = time.time()<br>calTime = endTime - beginTime<br><br>totalTime = loadTime + calTime<br><br><span class="hljs-built_in">print</span>(device,<span class="hljs-string">&quot;\t\t%.5f\t\t%.5f\t\t%.5f&quot;</span>%(loadTime,calTime,totalTime))<br></code></pre></td></tr></table></figure><p>运行后如果电脑<s>突然燃起来🔥</s>，散热风扇开始疯狂转，说明已经在工作，如下图是我的电脑运行后的结果：</p><p><img src="/2023/04/19/Pytorch%E5%AE%89%E8%A3%85/pic9.png" alt="程序运行结果"></p><p>可以看到 cuda 加载数据 (使用显卡时需要将数据加载到显存中 ) 耗时较久，但计算时间相比 cpu 快很多。因此对于 I/O 密集型程序，用 cpu 可能好一些；而对于计算密集型程序，使用显卡或许会有奇效。</p><h2 id="安装完成">安装完成</h2><p>安装成功！开始 coding !😆</p>]]></content>
    
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>WanwanWork</title>
    <link href="/2023/04/11/WanwanWork/"/>
    <url>/2023/04/11/WanwanWork/</url>
    
    <content type="html"><![CDATA[<img src="/2023/04/11/WanwanWork/WanwanWork.png" class title="WanwanWork">]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
